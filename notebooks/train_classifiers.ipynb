{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "80b971e6-53f6-4740-8132-cf257be7346f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from discovery_utils.enrichment.crunchbase import _enrich_keyword_labels\n",
    "from discovery_utils.getters.horizon_scout import get_training_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "7bb84878",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from typing import Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d63d97ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_by_keywords(dataset: pd.DataFrame, mission: str) -> pd.DataFrame:\n",
    "    \"\"\"Classify mission relevance by keywords.\n",
    "    \n",
    "    Args:\n",
    "        dataset (pd.DataFrame): Dataset to be classified. Must have column \"text\" and \"id\".\n",
    "        mission (str): Mission ('AHL', 'ASF' or 'AFS')\n",
    "    \"\"\"\n",
    "    return (\n",
    "        dataset\n",
    "        .merge(_enrich_keyword_labels(dataset, mission).assign(prediction=1), how=\"left\", on=\"id\")\n",
    "        .fillna({\"prediction\": 0})\n",
    "        .assign(correct=lambda x: (x['relevant'] == x['prediction']))\n",
    "        .astype({\"correct\": int, \"prediction\": int})\n",
    "    )\n",
    "    \n",
    "\n",
    "def make_train_val_test_datasets(\n",
    "    dataset: pd.DataFrame,\n",
    "    random_state=int,\n",
    "    training_frac=float,\n",
    "    val_frac=float,\n",
    "    ) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Split the input DataFrame into non-overlapping training, validation, and test datasets.\n",
    "\n",
    "    First shuffle the dataset using a specified random state.\n",
    "    Then partitions the dataset into training, validation, and test sets.\n",
    "    The sum of `training_frac` and `val_frac` should be less than or equal to 1.\n",
    "    If the sum is less than 1, the remaining portion of the dataset becomes the test set.\n",
    "\n",
    "    Args:\n",
    "        dataset (pd.DataFrame): The complete dataset to be split.\n",
    "        random_state (int): A seed used by the random number generator for shuffling the data.\n",
    "        training_frac (float): The fraction of the dataset to allocate to the training set.\n",
    "        val_frac (float): The fraction of the dataset to allocate to the validation set.\n",
    "\n",
    "    Returns:\n",
    "        Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]: A tuple containing three DataFrames:\n",
    "        (training_dataset, val_dataset, test_dataset).\n",
    "    \"\"\"\n",
    "    shuffled_dataset = dataset.sample(frac=1, random_state=random_state)\n",
    "    training_size = int(len(shuffled_dataset) * training_frac)\n",
    "    val_size = int(len(shuffled_dataset) * val_frac)\n",
    "    training_dataset = shuffled_dataset[:training_size]\n",
    "    val_dataset = shuffled_dataset[training_size:training_size + val_size]\n",
    "    test_dataset = shuffled_dataset[training_size + val_size:]\n",
    "    return (training_dataset, val_dataset, test_dataset)\n",
    "\n",
    "def performance(dataset: pd.DataFrame, dataset_label:str) -> None:\n",
    "    \"\"\"Calculate and print Accuracy, TPR and TNR for dataset\"\"\"\n",
    "    accuracy = dataset.correct.sum() / len(dataset) \n",
    "    tpr = dataset.query(\"relevant == 1\").correct.sum() / len(dataset.query(\"relevant == 1\"))\n",
    "    tnr = dataset.query(\"relevant == 0\").correct.sum() / len(dataset.query(\"relevant == 0\"))\n",
    "    def float_to_percent(number: float) -> float:\n",
    "        return round(number * 100, 2)\n",
    "    print(f\"{dataset_label} -- Accuracy: {float_to_percent(accuracy)}\")\n",
    "    print(f\"{dataset_label} -- TPR: {float_to_percent(tpr)}\")\n",
    "    print(f\"{dataset_label} -- TNR: {float_to_percent(tnr)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dcd617d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AHL Test Set -- Accuracy: 69.23\n",
      "AHL Test Set -- TPR: 40.11\n",
      "AHL Test Set -- TNR: 98.85\n"
     ]
    }
   ],
   "source": [
    "ahl_training_data = get_training_data(\"AHL\")\n",
    "ahl_train, ahl_val, ahl_test = make_train_val_test_datasets(ahl_training_data, 13, 0.8, 0.1)\n",
    "ahl_test_with_preds = classify_by_keywords(ahl_test, \"AHL\")\n",
    "performance(ahl_test_with_preds, \"AHL Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "dfb8c230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASF Test Set -- Accuracy: 79.15\n",
      "ASF Test Set -- TPR: 64.97\n",
      "ASF Test Set -- TNR: 96.84\n"
     ]
    }
   ],
   "source": [
    "asf_training_data = get_training_data(\"ASF\")\n",
    "asf_train, asf_val, asf_test = make_train_val_test_datasets(asf_training_data, 13, 0.8, 0.1)\n",
    "asf_test_with_preds = classify_by_keywords(asf_test, \"ASF\")\n",
    "performance(asf_test_with_preds, \"ASF Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c01eaeab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AFS Test Set -- Accuracy: 88.03\n",
      "AFS Test Set -- TPR: 84.46\n",
      "AFS Test Set -- TNR: 94.0\n"
     ]
    }
   ],
   "source": [
    "afs_training_data = get_training_data(\"AFS\")\n",
    "afs_train, afs_val, afs_test = make_train_val_test_datasets(afs_training_data, 13, 0.8, 0.1)\n",
    "afs_test_with_preds = classify_by_keywords(afs_test, \"AFS\")\n",
    "performance(afs_test_with_preds, \"AFS Test Set\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e637250a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
