{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4110ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_positive_training_data(positive_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads and preprocesses positive training data from a CSV file.\n",
    "    \n",
    "    Args:\n",
    "        positive_path (str): The file path to the CSV containing positive samples.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the processed positive\n",
    "            training data, with duplicates and NA values removed,\n",
    "            and a 'relevant' column set to 1.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        pd.read_csv(positive_path)\n",
    "        [[\"id\", \"text\"]]\n",
    "        .dropna(subset=[\"id\"])\n",
    "        .drop_duplicates(subset=[\"id\"])\n",
    "        .assign(relevant=1)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "def make_negative_training_data(\n",
    "    data: pd.DataFrame,\n",
    "    random_state: int,\n",
    "    n_samples: int) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Samples and labels negative training data from a given DataFrame.\n",
    "    \n",
    "    Args:\n",
    "        data (pd.DataFrame): The DataFrame to sample from.\n",
    "        random_state (int): A seed for the random number generator to ensure reproducibility.\n",
    "        n_samples (int): The number of samples to draw.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame of sampled negative data, with a 'relevant' column set to 0.\n",
    "    \"\"\"\n",
    "    return (\n",
    "        data\n",
    "        .sample(n_samples, random_state=random_state)\n",
    "        .assign(relevant=0)\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "def make_training_data(\n",
    "    positive_training_data: pd.DataFrame,\n",
    "    negative_data_list: list,\n",
    "    negative_data_frac_list: list,\n",
    "    random_state: int\n",
    "    ) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Combines positive and negative training data into a single dataset.\n",
    "    \n",
    "    Args:\n",
    "        positive_training_data (pd.DataFrame): DataFrame containing the positive samples.\n",
    "        negative_data_list (list): A list of DataFrames from which negative samples will be drawn.\n",
    "        negative_data_frac_list (list): A list of fractions dictating the proportion of negative samples\n",
    "                                        to draw relative to the number of positive samples.\n",
    "        random_state (int): Seed for the random number generator used in sampling.\n",
    "        \n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing both positive and negative training data.\n",
    "    \"\"\"\n",
    "    training_data = [positive_training_data]\n",
    "    positive_training_data_len = len(positive_training_data)\n",
    "    negative_data_n_samples_list = [int(positive_training_data_len * frac) for frac in negative_data_frac_list]\n",
    "    for negative_data, negative_data_n_samples in zip(negative_data_list, negative_data_n_samples_list):\n",
    "        negative_training_data = make_negative_training_data(negative_data, random_state, negative_data_n_samples)\n",
    "        training_data.append(negative_training_data)\n",
    "    return pd.concat(training_data).reset_index(drop=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0dbae9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths (upload this data to S3 and write getters for it)\n",
    "afs_pos_path = \"training_data_inputs/Training data for mission classifier (positive samples only) - AFS.csv\"\n",
    "ahl_pos_path = \"training_data_inputs/Training data for mission classifier (positive samples only) - AHL.csv\"\n",
    "asf_pos_path = \"training_data_inputs/Training data for mission classifier (positive samples only) - ASF.csv\"\n",
    "cb_orgs_path = \"training_data_inputs/cb_organizations_2024-04-17.parquet\"\n",
    "afs_extra_path = \"training_data_inputs/relevance_labels_eval_annotated_afs.jsonl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "251fdc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load positive training data\n",
    "afs_positive_training_data = get_positive_training_data(afs_pos_path)\n",
    "ahl_positive_training_data = get_positive_training_data(ahl_pos_path)\n",
    "asf_positive_training_data = get_positive_training_data(asf_pos_path)\n",
    "# Load crunchbase orgs data which will used to sample negative training data\n",
    "cb_orgs = (\n",
    "    pd.read_parquet(\"training_data_inputs/cb_organizations_2024-04-17.parquet\")\n",
    "    .query(\"founded_on >= '2021-01-01'\")\n",
    "    .query(\"country_code == 'GBR'\")\n",
    "    .query(\"short_description.notna()\")\n",
    "    [[\"id\", \"short_description\"]]\n",
    "    .rename(columns={\"short_description\": \"text\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61ef4e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training data for each mission\n",
    "afs_training_data = make_training_data(\n",
    "    positive_training_data=afs_positive_training_data,\n",
    "    negative_data_list=[ahl_positive_training_data, asf_positive_training_data, cb_orgs],\n",
    "    negative_data_frac_list=[0.15, 0.15, 0.7],\n",
    "    random_state=1\n",
    "    )\n",
    "\n",
    "ahl_training_data = make_training_data(\n",
    "    positive_training_data=ahl_positive_training_data,\n",
    "    negative_data_list=[afs_positive_training_data, asf_positive_training_data, cb_orgs],\n",
    "    negative_data_frac_list=[0.15, 0.15, 0.7],\n",
    "    random_state=2\n",
    "    )\n",
    "\n",
    "asf_training_data = make_training_data(\n",
    "    positive_training_data=asf_positive_training_data,\n",
    "    negative_data_list=[afs_positive_training_data, ahl_positive_training_data, cb_orgs],\n",
    "    negative_data_frac_list=[0.15, 0.15, 0.7],\n",
    "    random_state=3\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c77e79bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3k/l470x4813z77v8j34_6rt19w0000gn/T/ipykernel_4908/3701946843.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  .replace({'prediction': {'Not-relevant': 0, 'Relevant': 1}})\n"
     ]
    }
   ],
   "source": [
    "# Create extra training data for AFS from ISS 3\n",
    "with open(afs_extra_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "parsed_data = [json.loads(line) for line in lines]\n",
    "afs_extra_training_data = (\n",
    "    pd.DataFrame(parsed_data)\n",
    "    [[\"id\", \"text\", \"prediction\"]]\n",
    "    .query(\"prediction != 'Not-specified'\")\n",
    "    .replace({'prediction': {'Not-relevant': 0, 'Relevant': 1}})\n",
    "    .rename(columns={\"prediction\": \"relevant\"})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a08c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add extra training data to AFS\n",
    "afs_training_data = pd.concat([afs_training_data, afs_extra_training_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec0cba36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save training datasets for each mission to csv (change this to save to S3 / write getters to get training data)\n",
    "afs_training_data.to_csv(\"training_data_outputs/afs_training_data.csv\", index=False)\n",
    "ahl_training_data.to_csv(\"training_data_outputs/ahl_training_data.csv\", index=False)\n",
    "asf_training_data.to_csv(\"training_data_outputs/asf_training_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2feb2a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from discovery_utils.utils import s3\n",
    "\n",
    "# bucket_name = s3.BUCKET_NAME_RAW  # or directly \"your-bucket-name\"\n",
    "# file_path = \"data/crunchbase/Crunchbase_2024-04-17/organizations.parquet\"\n",
    "# client = s3.s3_client()\n",
    "\n",
    "# df = s3._download_obj(\n",
    "#     s3_client=client,\n",
    "#     bucket=bucket_name,\n",
    "#     path_from=file_path,\n",
    "#     download_as=\"dataframe\"\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
