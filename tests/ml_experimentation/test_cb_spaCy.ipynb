{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define base name\n",
    "base_name = \"organization_descriptions\"\n",
    "\n",
    "data_path = f\"/Users/tom.willcocks/Downloads/{base_name}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if base_name == 'organization_descriptions':\n",
    "    col = \"description\"\n",
    "elif base_name == 'organizations':\n",
    "    col = \"short_description\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "df = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1399685, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'description' column to strings, replacing NaN values with an empty string\n",
    "sample_descriptions = df[col].fillna('').astype(str).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "714\n"
     ]
    }
   ],
   "source": [
    "# Add a boolean column to the DataFrame indicating whether \"heat pump\" is in the description\n",
    "df['contains_heat_pump'] = df[col].str.contains(\"heat pump\", case=False)\n",
    "\n",
    "# Print the sum of the new boolean column to see how many descriptions contain \"heat pump\"\n",
    "print(df['contains_heat_pump'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Active pipeline components: ['tok2vec', 'textcat']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import random\n",
    "\n",
    "model_path = \"/Users/tom.willcocks/Documents/code/discovery_utils/tests/heat_pump_model_spacy\"\n",
    "\n",
    "# Disable all components except 'textcat' when loading the model\n",
    "components_to_disable = ['tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
    "nlp = spacy.load(model_path, disable=components_to_disable)\n",
    "\n",
    "# Verify which components are active after disabling\n",
    "print(\"Active pipeline components:\", nlp.pipe_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing descriptions...\n",
      "Processing complete: 1.0%\n",
      "Processing complete: 2.0%\n",
      "Processing complete: 3.0%\n",
      "Processing complete: 4.0%\n",
      "Processing complete: 5.0%\n",
      "Processing complete: 6.0%\n",
      "Processing complete: 7.0%\n",
      "Processing complete: 8.0%\n",
      "Processing complete: 9.0%\n",
      "Processing complete: 10.0%\n",
      "Processing complete: 11.0%\n",
      "Processing complete: 12.0%\n",
      "Processing complete: 13.0%\n",
      "Processing complete: 14.0%\n",
      "Processing complete: 15.0%\n",
      "Processing complete: 16.0%\n",
      "Processing complete: 17.0%\n",
      "Processing complete: 18.0%\n",
      "Processing complete: 19.0%\n",
      "Processing complete: 20.0%\n",
      "Processing complete: 21.0%\n",
      "Processing complete: 22.0%\n",
      "Processing complete: 23.0%\n",
      "Processing complete: 24.0%\n",
      "Processing complete: 25.0%\n",
      "Processing complete: 26.0%\n",
      "Processing complete: 27.0%\n",
      "Processing complete: 28.0%\n",
      "Processing complete: 29.0%\n",
      "Processing complete: 30.0%\n",
      "Processing complete: 31.0%\n",
      "Processing complete: 32.0%\n",
      "Processing complete: 33.0%\n",
      "Processing complete: 34.0%\n",
      "Processing complete: 35.0%\n",
      "Processing complete: 36.0%\n",
      "Processing complete: 37.0%\n",
      "Processing complete: 38.0%\n",
      "Processing complete: 39.0%\n",
      "Processing complete: 40.0%\n",
      "Processing complete: 41.0%\n",
      "Processing complete: 42.0%\n",
      "Processing complete: 43.0%\n",
      "Processing complete: 44.0%\n",
      "Processing complete: 45.0%\n",
      "Processing complete: 46.0%\n",
      "Processing complete: 47.0%\n",
      "Processing complete: 48.0%\n",
      "Processing complete: 49.0%\n",
      "Processing complete: 50.0%\n",
      "Processing complete: 51.0%\n",
      "Processing complete: 52.0%\n",
      "Processing complete: 53.0%\n",
      "Processing complete: 54.0%\n",
      "Processing complete: 55.0%\n",
      "Processing complete: 56.0%\n",
      "Processing complete: 57.0%\n",
      "Processing complete: 58.0%\n",
      "Processing complete: 59.0%\n",
      "Processing complete: 60.0%\n",
      "Processing complete: 61.0%\n",
      "Processing complete: 62.0%\n",
      "Processing complete: 63.0%\n",
      "Processing complete: 64.0%\n",
      "Processing complete: 65.0%\n",
      "Processing complete: 66.0%\n",
      "Processing complete: 67.0%\n",
      "Processing complete: 68.0%\n",
      "Processing complete: 69.0%\n",
      "Processing complete: 70.0%\n",
      "Processing complete: 71.0%\n",
      "Processing complete: 72.0%\n",
      "Processing complete: 73.0%\n",
      "Processing complete: 74.0%\n",
      "Processing complete: 75.0%\n",
      "Processing complete: 76.0%\n",
      "Processing complete: 77.0%\n",
      "Processing complete: 78.0%\n",
      "Processing complete: 79.0%\n",
      "Processing complete: 80.0%\n",
      "Processing complete: 81.0%\n",
      "Processing complete: 82.0%\n",
      "Processing complete: 83.0%\n",
      "Processing complete: 84.0%\n",
      "Processing complete: 85.0%\n",
      "Processing complete: 86.0%\n",
      "Processing complete: 87.0%\n",
      "Processing complete: 88.0%\n",
      "Processing complete: 89.0%\n",
      "Processing complete: 90.0%\n",
      "Processing complete: 91.0%\n",
      "Processing complete: 92.0%\n",
      "Processing complete: 93.0%\n",
      "Processing complete: 94.0%\n",
      "Processing complete: 95.0%\n",
      "Processing complete: 96.0%\n",
      "Processing complete: 97.0%\n",
      "Processing complete: 98.0%\n",
      "Processing complete: 99.0%\n",
      "Number of companies about heat pumps: 0\n"
     ]
    }
   ],
   "source": [
    "# Ensure descriptions are strings, replacing NaN values with an empty string\n",
    "df[col] = df[col].fillna('').astype(str)\n",
    "\n",
    "# Process descriptions and predict the category with nlp.pipe for efficient batch processing\n",
    "# Initialize a list to store the classification results\n",
    "classification_results = []\n",
    "\n",
    "# Calculate total number of documents for progress tracking\n",
    "total_docs = len(df[col])\n",
    "percent_increment = total_docs / 100  # 1% of total\n",
    "\n",
    "print(\"Processing descriptions...\")\n",
    "\n",
    "# Use nlp.pipe for efficient processing and keep track of progress\n",
    "for i, doc in enumerate(nlp.pipe(df[col]), start=1):\n",
    "    # Update on each percentage increment\n",
    "    if i % percent_increment < 1:\n",
    "        print(f\"Processing complete: {i / total_docs * 100:.1f}%\")\n",
    "    \n",
    "    # Assuming your model outputs a category 'HEAT_PUMP_RELEVANT' with a score\n",
    "    # Modify the category name as necessary based on your model's output\n",
    "    score = doc.cats.get(\"HEAT_PUMP_RELEVANT\", 0)\n",
    "    # Consider a document relevant to heat pumps if the score exceeds a certain threshold, e.g., 0.5\n",
    "    is_relevant = score > 0.5\n",
    "    classification_results.append(is_relevant)\n",
    "\n",
    "# Add the model's relevance determination back to the DataFrame\n",
    "df['heat_pump_classifier'] = classification_results\n",
    "\n",
    "# Count how many companies are identified as being about heat pumps by the model\n",
    "heat_pump_companies_count = df['heat_pump_classifier'].sum()\n",
    "print(f\"Number of companies about heat pumps: {heat_pump_companies_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame saved as heatpump_organization_descriptions_20240321-134557.csv\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Generate a timestamp\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# Define the file name with the timestamp\n",
    "file_name = f\"heatpump_{base_name}_{timestamp}.csv\"\n",
    "\n",
    "# Select only the specified columns\n",
    "df = df[['id', 'name', col, 'heat_pump_spaCy']]\n",
    "\n",
    "# Save the DataFrame to a CSV file with the timestamped file name\n",
    "df.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"DataFrame saved as {file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The desired number of samples for each category\n",
    "# desired_samples = 3\n",
    "\n",
    "# # Initialize lists to store positives and negatives\n",
    "# positives = []\n",
    "# negatives = []\n",
    "\n",
    "# # Dynamically adjust the sample size for efficiency\n",
    "# sample_size = 1000  # Start with a smaller sample size\n",
    "# while len(positives) < desired_samples or len(negatives) < desired_samples:\n",
    "#     random_sample = random.sample(descriptions_list, sample_size)\n",
    "#     for doc in nlp.pipe(random_sample, batch_size=500):\n",
    "#         # Check if enough samples have been collected\n",
    "#         if len(positives) >= desired_samples and len(negatives) >= desired_samples:\n",
    "#             break\n",
    "#         # Classify and store the document based on its category\n",
    "#         if doc.cats[\"RELEVANT\"] >= 0.5:  # Adjust threshold as needed\n",
    "#             positives.append(doc.text)\n",
    "#         else:\n",
    "#             negatives.append(doc.text)\n",
    "#     # Double the sample size for the next iteration if more samples are needed\n",
    "#     sample_size = min(sample_size * 2, 50000)  # Cap the sample size at 50,000\n",
    "\n",
    "# # Randomly sample 3 positives and 3 negatives for review\n",
    "# sample_positives = random.sample(positives, min(desired_samples, len(positives)))\n",
    "# sample_negatives = random.sample(negatives, min(desired_samples, len(negatives)))\n",
    "\n",
    "# # Review your samples by printing them one after the other\n",
    "# print(\"Sample RELEVANT:\")\n",
    "# for text in sample_positives:\n",
    "#     print(text)\n",
    "#     print(\"---\")  # Separator for readability\n",
    "\n",
    "# print(\"Sample NOT_RELEVANT:\")\n",
    "# for text in sample_negatives:\n",
    "#     print(text)\n",
    "#     print(\"---\")  # Separator for readability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_crunchbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
