{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 28\n",
      "0.5: 35\n",
      "1: 99\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/tom.willcocks/Downloads/Copy of ISS_technologies_to_review_August_10.xlsx\"\n",
    "df = pd.read_excel(path, sheet_name=\"Heat pumps\")\n",
    "\n",
    "print(\"0:\", (df[\"hit\"] == 0).sum())\n",
    "print(\"0.5:\", (df[\"hit\"] == 0.5).sum())\n",
    "print(\"1:\", (df[\"hit\"] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 28\n",
      "0.5: 0\n",
      "1: 134\n"
     ]
    }
   ],
   "source": [
    "# Make the 0.5s 1s\n",
    "\n",
    "df.loc[df[\"hit\"] == 0.5, \"hit\"] = 1\n",
    "\n",
    "print(\"0:\", (df[\"hit\"] == 0).sum())\n",
    "print(\"0.5:\", (df[\"hit\"] == 0.5).sum())\n",
    "print(\"1:\", (df[\"hit\"] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106 Abstracts are not currently available in GtR for all funded research. This is normally because the abstract was not required at the time of proposal submission, but may be because it included sensitive information such as personal details.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "new_path = \"/Users/tom.willcocks/Downloads/gtrprojects_sample.txt\"\n",
    "with open(new_path, 'r') as file:\n",
    "    neg_descriptions = json.load(file)\n",
    "    \n",
    "print(len(neg_descriptions), neg_descriptions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         description  hit\n",
      "0  Abstracts are not currently available in GtR f...    0\n",
      "1  With Covid-19 causing significant limitations ...    0\n",
      "2  Laser peening (LP) is a relatively new surface...    0\n",
      "3  Doctoral Training Partnerships: a range of pos...    0\n",
      "4  Applications are invited for a PhD position in...    0\n"
     ]
    }
   ],
   "source": [
    "# Create a new DataFrame from neg_descriptions\n",
    "df_negs = pd.DataFrame({\n",
    "    'description': neg_descriptions,\n",
    "    'hit': [0] * len(neg_descriptions)\n",
    "})\n",
    "\n",
    "print(df_negs.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 134\n",
      "0.5: 0\n",
      "1: 134\n"
     ]
    }
   ],
   "source": [
    "# Use pd.concat to append the new records to the original DataFrame\n",
    "df = pd.concat([df, df_negs], ignore_index=True)\n",
    "\n",
    "print(\"0:\", (df[\"hit\"] == 0).sum())\n",
    "print(\"0.5:\", (df[\"hit\"] == 0.5).sum())\n",
    "print(\"1:\", (df[\"hit\"] == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Check if the current record in the \"description\" column is not a string\n",
    "    if not isinstance(row[\"description\"], str):\n",
    "        # Print the record (or index) that isn't a string\n",
    "        print(f\"Record at index {index} is not a string: {row['description']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> 268 384\n"
     ]
    }
   ],
   "source": [
    "# Sentences are encoded by calling model.encode()\n",
    "embeddings = model.encode(df[\"description\"])\n",
    "\n",
    "print(type(embeddings),len(embeddings),len(embeddings[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Your embeddings array is X, and the \"hit\" column in your DataFrame is y\n",
    "X = embeddings\n",
    "y = df[\"hit\"].values\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Initialize the Logistic Regression classifier\n",
    "# The 'max_iter' parameter specifies the maximum number of iterations taken for the solvers to converge\n",
    "clf = LogisticRegression(max_iter=100, random_state=42)\n",
    "\n",
    "# Train the model on the training set\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate and print the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8888888888888888\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.89      0.81      0.85        21\n",
      "         1.0       0.89      0.94      0.91        33\n",
      "\n",
      "    accuracy                           0.89        54\n",
      "   macro avg       0.89      0.87      0.88        54\n",
      "weighted avg       0.89      0.89      0.89        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Make predictions on the testing set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Additionally, you can print a classification report for a more detailed performance analysis\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/Users/tom.willcocks/Documents/code/discovery_utils/tests/ml_experimentation/heat_pump_model_logreg.joblib']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "# Save the model to a file\n",
    "model_path = \"/Users/tom.willcocks/Documents/code/discovery_utils/tests/ml_experimentation/heat_pump_model_logreg.joblib\"\n",
    "dump(clf, model_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
