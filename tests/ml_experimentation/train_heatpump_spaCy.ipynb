{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0                                doc_id  \\\n",
      "0           0  B2F5CBB1-51AC-4CE2-8104-FA8674976404   \n",
      "1           1  933BEB0C-39DF-42AF-8F9C-23E437E537F9   \n",
      "2           2  E321CDF8-E847-4D0A-8037-33980D2BCA08   \n",
      "3           3  6913D6F8-AFD1-4660-835E-EEF3D930BB38   \n",
      "4           4  98D9956B-7F40-4B33-9C19-72C014CFE4A1   \n",
      "\n",
      "                                               title  \\\n",
      "0  High energy density heat storage materials for...   \n",
      "1  Development of a new generation of high effici...   \n",
      "2  Integrating Heat Pumps with Novel Solar Therma...   \n",
      "3  Solar-Thermal Heat-Pump Combination System - S...   \n",
      "4  Heat supply through Solar Thermochemical Resid...   \n",
      "\n",
      "                                         description source  cluster_id  \\\n",
      "0  Generating heat causes around one third of UK ...    gtr         257   \n",
      "1  The project's objectives are to assess the tec...    gtr         257   \n",
      "2  Our project will help reduce operational costs...    gtr         257   \n",
      "3  This project will deliver a combined renewable...    gtr         257   \n",
      "4  The Renewable Heat Incentive (RHI) scheme enco...    gtr         257   \n",
      "\n",
      "                                    cluster_keywords  global_topic_prob  \\\n",
      "0  ['heat', 'thermal', 'heating', 'cooling', 'sol...           0.450659   \n",
      "1  ['heat', 'thermal', 'heating', 'cooling', 'sol...           0.259477   \n",
      "2  ['heat', 'thermal', 'heating', 'cooling', 'sol...           0.320840   \n",
      "3  ['heat', 'thermal', 'heating', 'cooling', 'sol...           0.415521   \n",
      "4  ['heat', 'thermal', 'heating', 'cooling', 'sol...           0.497332   \n",
      "\n",
      "   local_topic_prob  hit                                        Unnamed: 10  \n",
      "0          0.677104  0.0                                                NaN  \n",
      "1          0.538921  1.0                                                NaN  \n",
      "2          0.521987  1.0                                                NaN  \n",
      "3          0.516483  1.0                                                NaN  \n",
      "4          0.510440  0.0  This seems to be solar thermal and seems simil...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "path = \"/Users/tom.willcocks/Downloads/Copy of ISS_technologies_to_review_August_10.xlsx\"\n",
    "df = pd.read_excel(path, sheet_name=\"Heat pumps\")\n",
    "\n",
    "print(df.head())  # Display the first few rows of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Concatenate all tabs into one dataframe\n",
    "\n",
    "# # Exclude the \"Notes\" tab\n",
    "# try:\n",
    "#     del all_sheets[\"Waste heat\"]\n",
    "#     del all_sheets[\"Notes\"]\n",
    "# except:\n",
    "#     pass\n",
    "\n",
    "# # Find common columns across all sheets\n",
    "# common_columns = set.intersection(*(set(df.columns) for df in all_sheets.values()))\n",
    "\n",
    "# # Filter DataFrames to only include common columns\n",
    "# filtered_dfs = [df[list(common_columns)] for df in all_sheets.values()]\n",
    "\n",
    "# # Concatenate all filtered DataFrames\n",
    "# concatenated_df = pd.concat(filtered_dfs, ignore_index=True)\n",
    "\n",
    "# df = concatenated_df\n",
    "\n",
    "# print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0            0\n",
       "doc_id                0\n",
       "title                 0\n",
       "description           0\n",
       "source                0\n",
       "cluster_id            0\n",
       "cluster_keywords      0\n",
       "global_topic_prob     0\n",
       "local_topic_prob     15\n",
       "hit                   0\n",
       "Unnamed: 10          43\n",
       "dtype: int64"
      ]
     },
     "execution_count": 368,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 11)"
      ]
     },
     "execution_count": 369,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generating heat causes around one third of UK ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The project's objectives are to assess the tec...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Our project will help reduce operational costs...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>This project will deliver a combined renewable...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Renewable Heat Incentive (RHI) scheme enco...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  hit\n",
       "0  Generating heat causes around one third of UK ...  0.0\n",
       "1  The project's objectives are to assess the tec...  1.0\n",
       "2  Our project will help reduce operational costs...  1.0\n",
       "3  This project will deliver a combined renewable...  1.0\n",
       "4  The Renewable Heat Incentive (RHI) scheme enco...  0.0"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df[['description', 'hit']].dropna()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tok2vec', 'tagger', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']"
      ]
     },
     "execution_count": 372,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "textcat = nlp.add_pipe(\"textcat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.add_label(\"RELEVANT\")\n",
    "textcat.add_label(\"NOT_RELEVANT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('RELEVANT', 'NOT_RELEVANT')"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textcat.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to tuples of (text, label)\n",
    "\n",
    "df['tuples'] = df.apply(lambda row: (row['description'], row['hit']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>description</th>\n",
       "      <th>hit</th>\n",
       "      <th>tuples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generating heat causes around one third of UK ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>(Generating heat causes around one third of UK...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         description  hit  \\\n",
       "0  Generating heat causes around one third of UK ...  0.0   \n",
       "\n",
       "                                              tuples  \n",
       "0  (Generating heat causes around one third of UK...  "
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['tuples'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(\"Generating heat causes around one third of UK greenhouse emissions. The UK 2011 Carbon Plan requires virtually zero carbon buildings in the UK by 2050. Heat storage is a key component when generating heat from intermittent renewable sources or to shift heat production to off-peak periods while heat consumption remains on-peak. Today, water-based thermal stores are commmon in the UK, but their large size make them undesirable or impossible to fit in smaller dwellings. Sunamp's heat battery technology uses Phase Change Materials to shrink heat storage to around one quarter the size of equivalent hot water thermal stores. This project allows Sunamp to rapidly increase the range of temperatures at which heat can be stored in Phase Change Materials, investigating materials with high effectivenes in the 75-90&deg;C range to be used in tandem with high-temperature renewable heat sources, e.g. solar thermal systems, CHP, CO2 heat pumps and biomass boilers.\", 0.0)\n",
      "162\n"
     ]
    }
   ],
   "source": [
    "print(data[0])\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts, labels = zip(*data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating heat causes around one third of UK greenhouse emissions. The UK 2011 Carbon Plan requires virtually zero carbon buildings in the UK by 2050. Heat storage is a key component when generating heat from intermittent renewable sources or to shift heat production to off-peak periods while heat consumption remains on-peak. Today, water-based thermal stores are commmon in the UK, but their large size make them undesirable or impossible to fit in smaller dwellings. Sunamp's heat battery technology uses Phase Change Materials to shrink heat storage to around one quarter the size of equivalent hot water thermal stores. This project allows Sunamp to rapidly increase the range of temperatures at which heat can be stored in Phase Change Materials, investigating materials with high effectivenes in the 75-90&deg;C range to be used in tandem with high-temperature renewable heat sources, e.g. solar thermal systems, CHP, CO2 heat pumps and biomass boilers.\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(texts[0])\n",
    "print(labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 28\n",
      "0.5: 0\n",
      "1: 134\n"
     ]
    }
   ],
   "source": [
    "# Handle 0.5 labels\n",
    "\n",
    "# # Convert labels to a list to modify it\n",
    "# labels_list = list(labels)\n",
    "\n",
    "# # Filter out all instances of 0.5 from the list\n",
    "# labels_list = [label for label in labels_list if label != 0.5]\n",
    "\n",
    "# # Convert back to a tuple if needed\n",
    "# labels = tuple(labels_list)\n",
    "\n",
    "# # Now, print your counts\n",
    "# print(\"0: \" + str(labels_list.count(0)))\n",
    "# print(\"0.5: \" + str(labels_list.count(0.5)))\n",
    "# print(\"1: \" + str(labels_list.count(1)))\n",
    "\n",
    "\n",
    "# Convert labels to a list to modify it\n",
    "labels_list = list(labels)\n",
    "\n",
    "# Modify the list as needed\n",
    "for i in range(len(labels_list)):\n",
    "    if labels_list[i] == 0.5:\n",
    "        labels_list[i] = 1\n",
    "\n",
    "# Convert back to a tuple if needed\n",
    "labels = tuple(labels_list)\n",
    "\n",
    "# Now, print your counts\n",
    "print(\"0: \" + str(labels_list.count(0)))\n",
    "print(\"0.5: \" + str(labels_list.count(0.5)))\n",
    "print(\"1: \" + str(labels_list.count(1)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1, 1.0, 1.0, 1.0, 1, 1.0, 1, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1, 1.0, 1, 1.0, 1, 1, 0.0, 1.0, 0.0, 1, 1.0, 1, 1.0, 1, 1.0, 1.0, 1, 1, 1, 1, 1, 1, 1, 1.0, 1.0, 0.0, 1, 1, 1.0, 1, 1, 1, 1, 1, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1, 1, 1.0, 1, 0.0, 1.0, 1.0, 1, 1.0, 1.0, 1.0, 1, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1, 1, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 1, 1.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1, 1.0, 1.0, 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "new_path = \"/Users/tom.willcocks/Downloads/gtrprojects_sample.txt\"\n",
    "with open(new_path, 'r') as file:\n",
    "    loaded_list = json.load(file)\n",
    "    \n",
    "print(len(loaded_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_samples = [(item, 0) for item in loaded_list]\n",
    "neg_texts, neg_labels = zip(*neg_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Abstracts are not currently available in GtR for all funded research. This is normally because the abstract was not required at the time of proposal submission, but may be because it included sensitive information such as personal details.\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(neg_texts[0])\n",
    "print(neg_labels[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Append the negative samples to the positive samples\n",
    "# Assuming texts, neg_texts, samples, and neg_samples are lists\n",
    "texts += neg_texts\n",
    "labels += neg_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = []\n",
    "for y in labels:\n",
    "    if(bool(y)):\n",
    "        cats.append({\"RELEVANT\": True, \"NOT_RELEVANT\":False})\n",
    "    else:\n",
    "        cats.append({\"RELEVANT\": False, \"NOT_RELEVANT\":True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = texts\n",
    "Y = cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(X))\n",
    "len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the data\n",
    "all_data = list(zip(X,[{'cats': cats} for cats in Y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(all_data)):\n",
    "#     print(all_data[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "texts, annotations = zip(*all_data)  # Unzip the list of tuples\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, annotations, test_size=0.2, random_state=42)\n",
    "train_data = list(zip(X_train, y_train))\n",
    "test_data = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"Generating heat causes around one third of UK greenhouse emissions. The UK 2011 Carbon Plan requires virtually zero carbon buildings in the UK by 2050. Heat storage is a key component when generating heat from intermittent renewable sources or to shift heat production to off-peak periods while heat consumption remains on-peak. Today, water-based thermal stores are commmon in the UK, but their large size make them undesirable or impossible to fit in smaller dwellings. Sunamp's heat battery technology uses Phase Change Materials to shrink heat storage to around one quarter the size of equivalent hot water thermal stores. This project allows Sunamp to rapidly increase the range of temperatures at which heat can be stored in Phase Change Materials, investigating materials with high effectivenes in the 75-90&deg;C range to be used in tandem with high-temperature renewable heat sources, e.g. solar thermal systems, CHP, CO2 heat pumps and biomass boilers.\",\n",
       " {'cats': {'RELEVANT': False, 'NOT_RELEVANT': True}})"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "268"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n",
      "Epoch : 0 \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1 \n",
      "Epoch : 2 \n",
      "Epoch : 3 \n",
      "Epoch : 4 \n",
      "Epoch : 5 \n",
      "Epoch : 6 \n",
      "Epoch : 7 \n",
      "Epoch : 8 \n",
      "Epoch : 9 \n"
     ]
    }
   ],
   "source": [
    "from spacy.util import minibatch, compounding\n",
    "from spacy.training import Example\n",
    "\n",
    "# Disable other components\n",
    "other_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'textcat']\n",
    "with nlp.disable_pipes(*other_pipes):  # only train textcat\n",
    "    optimizer = nlp.begin_training()\n",
    "    print(\"Training the model...\")\n",
    "\n",
    "    # Perform training\n",
    "    for i in range(n_iter):\n",
    "        print(\"Epoch : {} \".format(i))\n",
    "        losses = {}\n",
    "        # Create minibatches and convert texts and annotations to Example objects\n",
    "        batches = minibatch(train_data, size=compounding(4., 32., 1.001))\n",
    "        for batch in batches:\n",
    "            examples = [Example.from_dict(nlp.make_doc(text), ann) for text, ann in batch]\n",
    "            nlp.update(examples, sgd=optimizer, drop=0.2, losses=losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.to_disk(\"/Users/tom.willcocks/Documents/code/discovery_utils/tests/heat_pump_model_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"/Users/tom.willcocks/Documents/code/discovery_utils/tests/heat_pump_model_spacy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'RELEVANT': 0.9999397993087769, 'NOT_RELEVANT': 6.013893289491534e-05}"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_text = \"Heat pumps are a carbon footprint friendly way to heat the home.\"\n",
    "doc=nlp(test_text)\n",
    "doc.cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8595317725752509\n",
      "Category: RELEVANT, Precision: 0.8611111111111112, Recall: 0.9393939393939394\n",
      "Category: NOT_RELEVANT, Precision: 0.8888888888888888, Recall: 0.7619047619047619\n"
     ]
    }
   ],
   "source": [
    "# Testing the model\n",
    "test_examples = [Example.from_dict(nlp.make_doc(text), cats) for text, cats in test_data]\n",
    "\n",
    "# Evaluate the model\n",
    "scores = nlp.evaluate(test_examples)\n",
    "\n",
    "# Print evaluation scores\n",
    "print(f\"Accuracy: {scores['cats_score']}\")\n",
    "# Can also access 'cats_f_per_type', 'cats_macro_p', 'cats_macro_r', 'cats_macro_f', etc.\n",
    "\n",
    "# Printing precision and recall for each category\n",
    "for category, metrics in scores['cats_f_per_type'].items():\n",
    "    precision = metrics['p']\n",
    "    recall = metrics['r']\n",
    "    print(f\"Category: {category}, Precision: {precision}, Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\n",
      "============================= Pipeline Overview =============================\u001b[0m\n",
      "\n",
      "#   Component         Assigns               Requires   Scores             Retokenizes\n",
      "-   ---------------   -------------------   --------   ----------------   -----------\n",
      "0   tok2vec           doc.tensor                                          False      \n",
      "                                                                                     \n",
      "1   tagger            token.tag                        tag_acc            False      \n",
      "                                                                                     \n",
      "2   parser            token.dep                        dep_uas            False      \n",
      "                      token.head                       dep_las                       \n",
      "                      token.is_sent_start              dep_las_per_type              \n",
      "                      doc.sents                        sents_p                       \n",
      "                                                       sents_r                       \n",
      "                                                       sents_f                       \n",
      "                                                                                     \n",
      "3   attribute_ruler                                                       False      \n",
      "                                                                                     \n",
      "4   lemmatizer        token.lemma                      lemma_acc          False      \n",
      "                                                                                     \n",
      "5   ner               doc.ents                         ents_f             False      \n",
      "                      token.ent_iob                    ents_p                        \n",
      "                      token.ent_type                   ents_r                        \n",
      "                                                       ents_per_type                 \n",
      "                                                                                     \n",
      "6   textcat           doc.cats                         cats_score         False      \n",
      "                                                       cats_score_desc               \n",
      "                                                       cats_micro_p                  \n",
      "                                                       cats_micro_r                  \n",
      "                                                       cats_micro_f                  \n",
      "                                                       cats_macro_p                  \n",
      "                                                       cats_macro_r                  \n",
      "                                                       cats_macro_f                  \n",
      "                                                       cats_macro_auc                \n",
      "                                                       cats_f_per_type               \n",
      "\n",
      "\u001b[38;5;2mâœ” No problems found.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'summary': {'tok2vec': {'assigns': ['doc.tensor'],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'tagger': {'assigns': ['token.tag'],\n",
       "   'requires': [],\n",
       "   'scores': ['tag_acc'],\n",
       "   'retokenizes': False},\n",
       "  'parser': {'assigns': ['token.dep',\n",
       "    'token.head',\n",
       "    'token.is_sent_start',\n",
       "    'doc.sents'],\n",
       "   'requires': [],\n",
       "   'scores': ['dep_uas',\n",
       "    'dep_las',\n",
       "    'dep_las_per_type',\n",
       "    'sents_p',\n",
       "    'sents_r',\n",
       "    'sents_f'],\n",
       "   'retokenizes': False},\n",
       "  'attribute_ruler': {'assigns': [],\n",
       "   'requires': [],\n",
       "   'scores': [],\n",
       "   'retokenizes': False},\n",
       "  'lemmatizer': {'assigns': ['token.lemma'],\n",
       "   'requires': [],\n",
       "   'scores': ['lemma_acc'],\n",
       "   'retokenizes': False},\n",
       "  'ner': {'assigns': ['doc.ents', 'token.ent_iob', 'token.ent_type'],\n",
       "   'requires': [],\n",
       "   'scores': ['ents_f', 'ents_p', 'ents_r', 'ents_per_type'],\n",
       "   'retokenizes': False},\n",
       "  'textcat': {'assigns': ['doc.cats'],\n",
       "   'requires': [],\n",
       "   'scores': ['cats_score',\n",
       "    'cats_score_desc',\n",
       "    'cats_micro_p',\n",
       "    'cats_micro_r',\n",
       "    'cats_micro_f',\n",
       "    'cats_macro_p',\n",
       "    'cats_macro_r',\n",
       "    'cats_macro_f',\n",
       "    'cats_macro_auc',\n",
       "    'cats_f_per_type'],\n",
       "   'retokenizes': False}},\n",
       " 'problems': {'tok2vec': [],\n",
       "  'tagger': [],\n",
       "  'parser': [],\n",
       "  'attribute_ruler': [],\n",
       "  'lemmatizer': [],\n",
       "  'ner': [],\n",
       "  'textcat': []},\n",
       " 'attrs': {'token.tag': {'assigns': ['tagger'], 'requires': []},\n",
       "  'token.dep': {'assigns': ['parser'], 'requires': []},\n",
       "  'doc.ents': {'assigns': ['ner'], 'requires': []},\n",
       "  'doc.cats': {'assigns': ['textcat'], 'requires': []},\n",
       "  'token.ent_type': {'assigns': ['ner'], 'requires': []},\n",
       "  'doc.tensor': {'assigns': ['tok2vec'], 'requires': []},\n",
       "  'doc.sents': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.head': {'assigns': ['parser'], 'requires': []},\n",
       "  'token.ent_iob': {'assigns': ['ner'], 'requires': []},\n",
       "  'token.lemma': {'assigns': ['lemmatizer'], 'requires': []},\n",
       "  'token.is_sent_start': {'assigns': ['parser'], 'requires': []}}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.analyze_pipes(pretty=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "discovery_crunchbase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
